{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pneuly/whisper-asr-colab/blob/develop/whisper_asr_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYRELn5Rozs8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import threading\n",
    "import locale\n",
    "from joblib import Parallel, delayed\n",
    "from google.colab import files\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "os.environ[\"UV_PRERELEASE\"] = \"if-necessary-or-explicit\"\n",
    "os.environ[\"UV_SYSTEM_PYTHON\"] = \"true\"\n",
    "os.environ[\"UV_NO_PROGRESS\"] = \"true\"\n",
    "for var in [\"UV_BUILD_CONSTRAINT\", \"UV_CONSTRAINT\"]:\n",
    "    os.environ.pop(var, None)\n",
    "\n",
    "# Avoid unnecessary downgrades\n",
    "with open(\"override.txt\", \"w\") as f:\n",
    "    f.writelines(\"\"\"nvidia-cudnn-cu12\n",
    "nvidia-cublas-cu12\n",
    "nvidia-cuda-cupti-cu12\n",
    "nvidia-cuda-nvrtc-cu12\n",
    "nvidia-cuda-runtime-cu12\n",
    "nvidia-cufft-cu12\n",
    "nvidia-curand-cu12\n",
    "nvidia-cusolver-cu12\n",
    "nvidia-cusparse-cu12\n",
    "nvidia-nvjitlink-cu12\n",
    "nvidia-nccl-cu12\n",
    "\"\"\")\n",
    "os.environ[\"UV_OVERRIDE\"] = \"override.txt\"\n",
    "\n",
    "# @title Faster-Whisper Implementation on Google Colab{ display-mode: \"form\" }\n",
    "audio = 'https://www.youtube.com/live/UaDDdgpTch0'  # @param {type:\"string\"}\n",
    "download_format = \"mp3\"  # @param [\"\", \"mp3\", \"m4a\", \"aac\", \"vorbis\", \"opus\", \"wav\"] {allow-input: true}\n",
    "model_size = \"large-v3-turbo\" # @param [\"large-v3-turbo\", \"large-v3\", \"large-v2\", \"large\", \"medium\", \"small\", \"base\", \"tiny\"] {allow-input: true}\n",
    "diarization = True  # @param {type:\"boolean\"}\n",
    "HUGGING_FACE_TOKEN = \"\" # @param {type:\"string\"}\n",
    "password = \"\"  # @param {type:\"string\"}\n",
    "start_time = \"\"  # @param {type:\"string\"}\n",
    "end_time = \"\"  # @param {type:\"string\"}\n",
    "timestamp_offset = \"\"  # @param {type:\"string\"}\n",
    "skip_silence = True  # @param {type:\"boolean\"}\n",
    "hotwords = \"次に、これです。\"\n",
    "batch_size = 1\n",
    "realtime = False\n",
    "initial_prompt = \"\"\n",
    "prefix = None\n",
    "vad_filter = False\n",
    "files_to_download = []\n",
    "\n",
    "# ----- main routine ------\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "if diarization and HUGGING_FACE_TOKEN == \"\":\n",
    "    raise ValueError(\"Input your token to hf_token (https://huggingface.co/pyannote/speaker-diarization)\")\n",
    "\n",
    "if audio == \"\":\n",
    "    audio = list(files.upload())[0]\n",
    "\n",
    "!uv pip install git+https://github.com/pneuly/whisper-asr-colab.git@develop\n",
    "from whisper_asr_colab.audio import Audio # noqa: E402\n",
    "from faster_whisper.utils import download_model\n",
    "\n",
    "audio = Audio().from_path_or_url(audio)\n",
    "if start_time:\n",
    "    audio.start_time = start_time\n",
    "if end_time:\n",
    "    audio.end_time = end_time\n",
    "if download_format:\n",
    "    audio.download_format = download_format\n",
    "if password:\n",
    "    audio.password = password\n",
    "audio.verify_upload = False\n",
    "audio._load_audio()\n",
    "\n",
    "def _transcribe():\n",
    "    from whisper_asr_colab.worker import Worker\n",
    "    worker = Worker(\n",
    "        audio=audio,\n",
    "        model_size=model_size,\n",
    "        language=\"ja\",\n",
    "        diarization=diarization,\n",
    "        password=password,\n",
    "        initial_prompt=initial_prompt,\n",
    "        realtime=realtime,\n",
    "        batch_size=batch_size,\n",
    "        hugging_face_token=HUGGING_FACE_TOKEN,\n",
    "        hotwords=hotwords,\n",
    "        prefix=prefix,\n",
    "        vad_filter=False,\n",
    "        skip_silence=skip_silence,\n",
    "    )\n",
    "    if timestamp_offset:\n",
    "        worker.timestamp_offset = timestamp_offset\n",
    "    results = worker.run()\n",
    "    # gc GPU RAM\n",
    "    del worker\n",
    "    return results\n",
    "\n",
    "def _diarize():\n",
    "    !uv pip install pyannote.audio\n",
    "    from whisper_asr_colab.worker import Diarizer # noqa: E402\n",
    "    from torch.cuda import empty_cache\n",
    "    empty_cache()\n",
    "    diarizer = Diarizer(\n",
    "        audio=audio,\n",
    "        hugging_face_token = HUGGING_FACE_TOKEN,\n",
    "        )\n",
    "    diarizer.diarize()\n",
    "    return diarizer.integrate()\n",
    "\n",
    "def _convert_audio_if_needed():\n",
    "    input_path = audio.file_path\n",
    "    if not input_path.endswith(download_format):\n",
    "        !uv pip install ffmpeg-python\n",
    "        import ffmpeg\n",
    "        print(f\"Converting {input_path} to mp3 format.\")\n",
    "        base, _ = os.path.splitext(input_path)\n",
    "        output_path = base + '.' + download_format\n",
    "        ffmpeg.run(\n",
    "            ffmpeg.input(input_path).output(output_path),\n",
    "            overwrite_output=True\n",
    "        )\n",
    "        return output_path\n",
    "    return input_path\n",
    "\n",
    "stop_event = threading.Event()\n",
    "def _tail_log_file():\n",
    "    file_path = \"diarization_progress.txt\"\n",
    "    while not stop_event.is_set():\n",
    "        if not os.path.exists(file_path):\n",
    "            print(\"Waiting for transcribing to begin.\")\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "        with open(file_path, \"r\") as f:\n",
    "            while not stop_event.is_set():\n",
    "                line = f.readline()\n",
    "                if line:\n",
    "                    print(line.strip(), flush=True)\n",
    "                else:\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initializing FasterWhisper and pyannote.audio in the same\n",
    "    # namespace causes a crash or errors.\n",
    "    # To isolate them, FasterWhisper is launched in a separate\n",
    "    # process using joblib.\n",
    "    # Since multiprocessing is unreliable in Jupyter environments,\n",
    "    # joblib's 'loky' backend is required.\n",
    "    # However, loky suppresses stdout/stderr from child processes,\n",
    "    # so some workarounds are implemented.\n",
    "\n",
    "    download_model(model_size)\n",
    "    threading.Thread(target=_tail_log_file, daemon=True).start()\n",
    "    result = Parallel(n_jobs=2, backend=\"loky\", verbose=5)([delayed(_transcribe)()])\n",
    "    stop_event.set()\n",
    "    files_to_download.extend(result[0])\n",
    "\n",
    "    if diarization:\n",
    "        result_files = _diarize()\n",
    "        files_to_download.extend(result_files)\n",
    "\n",
    "    if audio.url:\n",
    "        # Add audio file to files_to_download\n",
    "        audio_file = _convert_audio_if_needed()\n",
    "        files_to_download.append(audio_file)\n",
    "\n",
    "    # Download files\n",
    "    from whisper_asr_colab.utils import download_from_colab\n",
    "    for file in files_to_download:\n",
    "        print(f\"Downloading {file}\")\n",
    "        download_from_colab(file)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
