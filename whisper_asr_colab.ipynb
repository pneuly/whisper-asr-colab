{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pneuly/whisper-asr-colab/blob/main/faster_whisper_share.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import fcntl\n",
        "import importlib.util\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import pip\n",
        "import numpy as np\n",
        "import torch\n",
        "from google.colab import files\n",
        "\n",
        "# @title 自動文字起こし（Wisper）{ display-mode: \"form\" }\n",
        "# @markdown 以下の設定項目を入力しセルを実行（Ctrl+Enter）<font color=\"red\">※設定項目の説明は下にあります</font>\n",
        "\n",
        "# @markdown #<b>設定</b>\n",
        "audiopath = 'https://www.youtube.com/watch?v=xAmEQOqtMvA'  # @param {type:\"string\"}\n",
        "model_size = \"large-v3\" # @param [\"large-v3\", \"large-v2\", \"large\", \"medium\", \"small\", \"base\", \"tiny\"] {allow-input: true}\n",
        "diarization = True  # @param {type:\"boolean\"}\n",
        "password = None  # @param {type:\"string\"}\n",
        "start_time = None  # @param {type:\"string\"}\n",
        "end_time = None  # @param {type:\"string\"}\n",
        "timestamp_offset = None  # @param {type:\"string\"}\n",
        "initial_prompt = \"定刻 なりましたので、 です。 ます。\"  # @param {type:\"string\"}\n",
        "realtime = False  # @param {type:\"boolean\"}\n",
        "CHUNK_SIZE = 20\n",
        "BATCH_SIZE = 16\n",
        "HUGGING_FACE_TOKEN = \"\"\n",
        "\n",
        "# @markdown ###<br/><b>〔設定の説明〕</b>\n",
        "# @markdown <b>audiopath:</b> 文字起こしする音声ファイルの場所<br/>\n",
        "# @markdown 　　Youtubeの場合： https://www.youtube.com/......<br/>\n",
        "# @markdown 　　手動で音声をアップロードした場合： 230401_1010.mp3 など<br/>\n",
        "# @markdown 　　（アップロード完了まで待って実行してください）<br/>\n",
        "# @markdown 　　<font color=\"red\">空欄の場合はファイルアップロードボタンが表示されます</font>\n",
        "# @markdown <br/><b>model_size:</b> 音声認識のモデルサイズ（mediumにすると少し精度が落ちるが早い）\n",
        "# @markdown <br/><b>diarization:</b> 発言者別の文字起こしファイルを作成するか（Falseにすると早い）\n",
        "# @markdown #### <br/><b><font color= \"blue\">以下は必要な場合のみ設定</font></b>\n",
        "# @markdown <b>password:</b> パスワードを指定（Webexなど）</b>\n",
        "# @markdown <br/><b>start_time:</b> 開始時間 hh:mm:ss</b>（指定しない場合は最初から）\n",
        "# @markdown <br/><b>end_time:</b> 終了時間 hh:mm:ss（指定しない場合は最後まで）\n",
        "# @markdown <br/><b>timestamp_offset:</b> タイムスタンプを指定の時間だけずらす hh:mm:ss（Noneの場合はstart_timeと連動）\n",
        "# @markdown <br/><b>initial_prompt:</b> キーワード（です。 ます。は句読点を付けるために入れています）\n",
        "# @markdown <br/><b>reatime: </b><font color=\"red\">ストリーミングをリアルタイムで文字起こしをする場合のみオンにしてください。</font>\n",
        "\n",
        "# ----- 以下変更不要 ------\n",
        "if audiopath == \"\":\n",
        "    audiopath = list(files.upload())[0]\n",
        "\n",
        "\n",
        "def pip_install(module_name: str, install_name=None):\n",
        "    if install_name is None:\n",
        "        install_name = module_name\n",
        "    if importlib.util.find_spec(module_name) is None:\n",
        "        pip.main([\"install\", \"-q\", install_name])\n",
        "\n",
        "\n",
        "def subprocess_progress(cmd: list):\n",
        "    p = subprocess.Popen(\n",
        "        cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=False\n",
        "    )\n",
        "    flag = fcntl.fcntl(p.stdout.fileno(), fcntl.F_GETFL)\n",
        "    fcntl.fcntl(p.stdout.fileno(), fcntl.F_SETFL, flag | os.O_NONBLOCK)\n",
        "    while True:\n",
        "        buf = p.stdout.read()\n",
        "        if buf is not None:\n",
        "            sys.stdout.write(buf)\n",
        "            sys.stdout.flush()\n",
        "        if p.poll() is not None:\n",
        "            break\n",
        "        time.sleep(0.5)\n",
        "\n",
        "\n",
        "def str2seconds(time_str):\n",
        "    for fmt in (\"%H:%M:%S\", \"%M:%S\", \"%S\", \"%H:%M:%S.%f\", \"%M:%S.%f\", \"%S.%f\"):\n",
        "        try:\n",
        "            return (\n",
        "                datetime.strptime(time_str, fmt) - datetime(1900, 1, 1)\n",
        "                ).total_seconds()\n",
        "        except ValueError:\n",
        "            pass\n",
        "    print(f\"Error: Unable to parse time string '{time_str}'\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def dl_audio(url, password=\"\"):\n",
        "    \"\"\"Download file from Internet\"\"\"\n",
        "    pip_install(\"yt_dlp\", \"yt-dlp\")\n",
        "    # YoutubeDLクラスを使うとダウンロードエラーが発生するため\n",
        "    # 外部コマンドを使用\n",
        "    options = [\"-x\", \"-S\", \"+acodec:mp4a\", \"-o\", \"%(title)s.%(ext)s\"]\n",
        "    if password:\n",
        "        options += [\"--video-password\", password]\n",
        "    outfilename = subprocess.run(\n",
        "        [\"yt-dlp\", \"--print\", \"filename\"] + options + [url],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "    ).stdout.strip()\n",
        "    subprocess_progress([\"yt-dlp\"] + options + [url])\n",
        "    return outfilename\n",
        "\n",
        "\n",
        "def format_timestamp(seconds: float):\n",
        "    # td = timedelta(seconds=seconds)\n",
        "    # return f\"{str(td)[:10]}\"\n",
        "    hours = seconds // 3600\n",
        "    remain = seconds - (hours * 3600)\n",
        "    minutes = remain // 60\n",
        "    seconds = remain - (minutes * 60)\n",
        "    return \"{:01}:{:02}:{:05.2f}\".format(int(hours), int(minutes), seconds)\n",
        "\n",
        "def time_segment_text(segment):\n",
        "    _offset_seconds = str2seconds(timestamp_offset) if timestamp_offset else 0.0\n",
        "    start = segment[\"start\"] + _offset_seconds\n",
        "    end = segment[\"end\"] + _offset_seconds\n",
        "    return (f\"[{format_timestamp(start)} - {format_timestamp(end)}]\")\n",
        "\n",
        "\n",
        "def add_timestamp(segment):\n",
        "    return (f\"{time_segment_text(segment)} {segment['text'].strip()}\")\n",
        "\n",
        "\n",
        "def fill_missing_speakers(segments):\n",
        "    prev = None\n",
        "    for item in segments:\n",
        "        if 'speaker' in item:\n",
        "            prev = item['speaker']\n",
        "        else:\n",
        "            item.update({'speaker' : prev})\n",
        "    return segments\n",
        "\n",
        "\n",
        "def combine_same_speaker(segments):\n",
        "    from itertools import groupby\n",
        "    segments = fill_missing_speakers(segments)\n",
        "    _grouped = [\n",
        "        list(g) for k, g in groupby(segments, lambda x: x[\"speaker\"])\n",
        "    ]\n",
        "    _combined = [\n",
        "        {\"start\" : segs[0][\"start\"],\n",
        "         \"end\" : segs[-1][\"end\"],\n",
        "         \"text\" : \"\\n\".join([seg[\"text\"] for seg in segs]).strip(),\n",
        "         \"speaker\" : segs[0][\"speaker\"],\n",
        "         } for segs in _grouped\n",
        "    ]\n",
        "    return _combined\n",
        "\n",
        "\n",
        "def open_stream(url):\n",
        "    command = [\"yt-dlp\", \"-g\", url, \"-x\", \"-S\", \"+acodec:mp4a\"]\n",
        "    audio_url = subprocess.check_output(command).decode(\"utf-8\").strip()\n",
        "    return subprocess.Popen(\n",
        "        [\n",
        "            \"ffmpeg\",\n",
        "            \"-i\", audio_url,\n",
        "            \"-vn\",\n",
        "            \"-f\", \"s16le\",\n",
        "            \"-acodec\", \"pcm_s16le\",\n",
        "            \"-ac\", \"1\",\n",
        "            \"-ar\", \"16000\",\n",
        "            \"-\",\n",
        "            \"-loglevel\", \"quiet\"\n",
        "        ],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE\n",
        "    )\n",
        "\n",
        "\n",
        "def realtime_transcribe(model, data, outfh, initial_prompt = \"です。 ます。\"):\n",
        "    previous_text = \"\"\n",
        "    segments, info =  model.transcribe(\n",
        "        np.frombuffer(data, np.int16).astype(np.float32) / 32768.0,\n",
        "        language='ja',\n",
        "        #vad_filter=True,\n",
        "        initial_prompt=initial_prompt)\n",
        "    for segment in segments:\n",
        "        print(segment.text)\n",
        "        outfh.write(segment.text + \"\\n\")\n",
        "        outfh.flush()\n",
        "        previous_text = segment.text\n",
        "    return previous_text\n",
        "\n",
        "\n",
        "# --- main ---\n",
        "# dl audio if needed\n",
        "dlaudio = False\n",
        "if not realtime:\n",
        "    if re.match(r\"^(https://).+\", audiopath):\n",
        "        dlaudio = True\n",
        "        # download and return file name\n",
        "        audiopath = dl_audio(audiopath, password)\n",
        "    else:\n",
        "        # ファイルサイズが小さい場合はアップロード途中の可能性があるためチェックする\n",
        "        filesize = os.path.getsize(audiopath)\n",
        "        if filesize < 10 ** 7:  # 10MB未満の場合\n",
        "            time.sleep(10)\n",
        "            filesize2 = os.path.getsize(audiopath)\n",
        "            if (filesize2 - filesize) > 0:\n",
        "                sys.exit(\n",
        "                    \"ファイルのアップロードが終わっていない可能性があります。アップロード完了後再度実行してください。\"\n",
        "                    )\n",
        "    # trim\n",
        "    if start_time or end_time:\n",
        "        pip_install(\"ffmpeg\", \"ffmpeg-python\")\n",
        "        import ffmpeg\n",
        "        if start_time and end_time:\n",
        "            input = ffmpeg.input(audiopath, ss=start_time, to=end_time)\n",
        "        elif not start_time and end_time:\n",
        "            input = ffmpeg.input(audiopath, to=end_time)\n",
        "        else:\n",
        "            input = ffmpeg.input(audiopath, ss=start_time)\n",
        "        input_base, input_ext = os.path.splitext(audiopath)\n",
        "        input_path = f\"{input_base}_trimmed{input_ext}\"\n",
        "        print(f\"trimming audio from {start_time} to {end_time}.\")\n",
        "        ffmpeg.output(input, input_path, acodec=\"copy\", vcodec=\"copy\").run(\n",
        "                overwrite_output=True\n",
        "                )\n",
        "    else:\n",
        "        input_path = audiopath\n",
        "\n",
        "\n",
        "# Transcribe\n",
        "if diarization and not realtime: # use WhisperX\n",
        "    pip_install(\"whisper\", \"openai-whisper\")\n",
        "    pip_install(\"whisperx\", \"git+https://github.com/m-bain/whisperx.git\")\n",
        "    import whisperx\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = whisperx.load_model(\n",
        "        model_size,\n",
        "        device=device,\n",
        "        compute_type=\"default\",\n",
        "        asr_options={\"initial_prompt\" : initial_prompt}\n",
        "    )\n",
        "    audio = whisperx.load_audio(input_path)\n",
        "    result = model.transcribe(\n",
        "        audio,\n",
        "        language=\"ja\",\n",
        "        print_progress=True,\n",
        "        chunk_size=CHUNK_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        )\n",
        "    segments = result[\"segments\"]\n",
        "else:  # use faster-whisper\n",
        "    pip_install(\"whisper\", \"openai-whisper\")\n",
        "    pip_install(\"faster_whisper\")\n",
        "    from faster_whisper import WhisperModel\n",
        "    model = WhisperModel(\n",
        "        model_size, compute_type=\"default\"  # default: equivalent, auto: fastest\n",
        "    )\n",
        "    if not realtime:\n",
        "        segments = model.transcribe(\n",
        "            input_path,\n",
        "            language=\"ja\",\n",
        "            vad_filter=True,\n",
        "            initial_prompt=initial_prompt,\n",
        "            without_timestamps=False,\n",
        "        )[0]\n",
        "        segments = [seg._asdict() for seg in segments]\n",
        "    #\n",
        "    # realtime trascription\n",
        "    #\n",
        "    if realtime:\n",
        "        pip_install(\"yt_dlp\", \"yt-dlp\")\n",
        "        process = open_stream(audiopath)\n",
        "        previous_text = \"\"\n",
        "        buffer = b\"\"\n",
        "        fh1 = open(\n",
        "            datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".txt\",\n",
        "            \"w\",\n",
        "            encoding=\"utf-8\"\n",
        "        )\n",
        "        while True:\n",
        "            audio_data = process.stdout.read(16000 * 2)\n",
        "            if process.poll() is not None:\n",
        "                realtime_transcribe(model, buffer, fh1, previous_text)\n",
        "                break\n",
        "\n",
        "            buffer += audio_data\n",
        "            if len(buffer) >= 16000 * 2 * 30:  # 30 seconds\n",
        "                #print(len(buffer))\n",
        "                realtime_transcribe(model, buffer, fh1, previous_text)\n",
        "                previous_text += \"です。 ます。\"\n",
        "                buffer = buffer[- 16000:]  # 0.5 seconds overlap\n",
        "            else:\n",
        "                time.sleep(0.1)\n",
        "        fh1.close()\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        sys.exit(0)\n",
        "\n",
        "# write results to text files\n",
        "fh1 = open(f\"{os.path.basename(input_path)}.txt\", \"w\", encoding=\"utf-8\")\n",
        "fh2 = open(f\"{os.path.basename(input_path)}（タイムスタンプ付）.txt\", \"w\", encoding=\"utf-8\")\n",
        "for segment in segments:\n",
        "    fh1.write(segment[\"text\"] + \"\\n\")\n",
        "    fh2.write(add_timestamp(segment) + \"\\n\")\n",
        "fh1.close()\n",
        "fh2.close()\n",
        "\n",
        "files.download(fh1.name)\n",
        "files.download(fh2.name)\n",
        "\n",
        "if diarization:\n",
        "# Diarize\n",
        "    diarize_model = whisperx.DiarizationPipeline(\n",
        "        use_auth_token=HUGGING_FACE_TOKEN,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    diarize_segments = diarize_model(input_path)\n",
        "    result = whisperx.assign_word_speakers(diarize_segments, result)\n",
        "    segments = [\n",
        "        {k: v for k, v in d.items() if k != 'words'}\n",
        "        for d in result[\"segments\"]]\n",
        "\n",
        "    segments = combine_same_speaker(segments)\n",
        "\n",
        "    fh3 = open(f\"{os.path.basename(input_path)}（発言者別）.txt\", \"w\", encoding=\"utf-8\")\n",
        "    for segment in segments:\n",
        "        fh3.write(time_segment_text(segment) + \" \")\n",
        "        try:\n",
        "            fh3.write(segment[\"speaker\"] + \"\\n\")\n",
        "        except:\n",
        "            fh3.write(\"\\n\")\n",
        "        fh3.write(segment[\"text\"].replace(\" \", \"\") + \"\\n\\n\")\n",
        "    fh3.close()\n",
        "    files.download(fh3.name)\n",
        "\n",
        "# gc GPU RAM\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Generate docx\n",
        "pip_install(\"docx\", \"python-docx\")\n",
        "from pathlib import Path\n",
        "from docx import Document\n",
        "from docx.oxml import OxmlElement\n",
        "from docx.oxml.ns import qn\n",
        "from docx.enum.style import WD_STYLE_TYPE\n",
        "from docx.enum.text import WD_LINE_SPACING, WD_ALIGN_PARAGRAPH\n",
        "from docx.shared import Pt, Mm, RGBColor\n",
        "\n",
        "DEFAULT_FONT_SIZE = 12\n",
        "SERIF_FONT = \"ＭＳ 明朝\"\n",
        "SANS_FONT = \"ＭＳ ゴシック\"\n",
        "\n",
        "def set_rFonts(style, key, value):\n",
        "    style._element.rPr.rFonts.set(qn(f'w:{key}'), value)\n",
        "\n",
        "def create_attribute(element, name, value):\n",
        "    element.set(qn(name), value)\n",
        "\n",
        "def add_page_number(run):\n",
        "    fldChar1 = OxmlElement('w:fldChar')\n",
        "    create_attribute(fldChar1, 'w:fldCharType', 'begin')\n",
        "    instrText = OxmlElement('w:instrText')\n",
        "    create_attribute(instrText, 'xml:space', 'preserve')\n",
        "    instrText.text = \"PAGE\"\n",
        "    fldChar2 = OxmlElement('w:fldChar')\n",
        "    create_attribute(fldChar2, 'w:fldCharType', 'end')\n",
        "    run._r.append(fldChar1)\n",
        "    run._r.append(instrText)\n",
        "    run._r.append(fldChar2)\n",
        "\n",
        "def txt_to_word(filename):\n",
        "    # Open the text file in read mode with utf8 encoding\n",
        "    with open(filename, 'r', encoding='utf8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Create a new Word document\n",
        "    doc = Document()\n",
        "    sec = doc.sections[-1]\n",
        "\n",
        "    sec.page_height = Mm(297)\n",
        "    sec.page_width = Mm(210)\n",
        "    sec.top_margin = Mm(20)\n",
        "    sec.bottom_margin = Mm(15)\n",
        "    sec.left_margin = Mm(25)\n",
        "    sec.right_margin = Mm(25)\n",
        "    sec.footer_distance = Mm(8)\n",
        "\n",
        "    style_normal = doc.styles['Normal']\n",
        "    style_normal.font.name = SERIF_FONT\n",
        "    style_normal.font.name_eastasia = SERIF_FONT\n",
        "    style_normal.font.size = Pt(DEFAULT_FONT_SIZE)\n",
        "\n",
        "    style_speaker = doc.styles[\"Heading 1\"]\n",
        "    style_speaker.font.color.rgb = RGBColor(0, 0, 0)\n",
        "    style_speaker.font.bold = False\n",
        "    style_speaker.font.name = SANS_FONT\n",
        "    set_rFonts(style_speaker, \"asciiTheme\", SANS_FONT)\n",
        "    style_speaker.font.size = Pt(DEFAULT_FONT_SIZE)\n",
        "    style_speaker.paragraph_format.space_before = Pt(DEFAULT_FONT_SIZE)\n",
        "    style_speaker.paragraph_format.space_after = Pt(0)\n",
        "    style_speaker.paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE\n",
        "\n",
        "    style_ts1 = doc.styles.add_style('発言1行目', WD_STYLE_TYPE.PARAGRAPH)\n",
        "    style_ts1.font.name = SERIF_FONT\n",
        "    style_ts1.font.name_eastasia = SERIF_FONT\n",
        "    style_ts1.font.size = Pt(DEFAULT_FONT_SIZE)\n",
        "    style_ts1.paragraph_format.space_before = Pt(0)\n",
        "    style_ts1.paragraph_format.space_after = Pt(0)\n",
        "    style_ts1.paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE\n",
        "    style_ts1.paragraph_format.first_line_indent = Pt(- DEFAULT_FONT_SIZE)\n",
        "\n",
        "    style_ts2 = doc.styles.add_style('発言2行目', WD_STYLE_TYPE.PARAGRAPH)\n",
        "    style_ts2.base_style = style_ts1\n",
        "    style_ts2.paragraph_format.first_line_indent = Pt(DEFAULT_FONT_SIZE)\n",
        "\n",
        "    sec.footer.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "    add_page_number(sec.footer.paragraphs[0].add_run())\n",
        "\n",
        "    # Process each line\n",
        "    pline_count = 0\n",
        "    for line in lines:\n",
        "        # Blank line\n",
        "        if line.strip() == \"\":\n",
        "            continue\n",
        "        # Time and speaker info\n",
        "        if line.startswith('['):\n",
        "            elements = line.split(' ')\n",
        "            speaker = elements[3].strip()\n",
        "            time = \" \".join(elements[:3])\n",
        "            doc.add_paragraph(speaker + ' ' + time, style=style_speaker)\n",
        "            pline_count = 1\n",
        "            continue\n",
        "        # Transcript\n",
        "        if pline_count == 1:\n",
        "            doc.add_paragraph(\"○　\", style=style_ts1)\n",
        "        else:\n",
        "            doc.add_paragraph(\"\", style=style_ts2)\n",
        "        doc.paragraphs[-1].add_run(line.strip())\n",
        "        pline_count += 1\n",
        "\n",
        "    outfile = f\"{Path(filename).stem}.docx\"\n",
        "    doc.save(outfile)\n",
        "    return outfile\n",
        "\n",
        "if diarization:\n",
        "    docxfile = txt_to_word(fh3.name)\n",
        "    files.download(docxfile)\n",
        "\n",
        "# DL audio file\n",
        "if dlaudio:\n",
        "    files.download(audiopath)\n"
      ],
      "metadata": {
        "id": "HYRELn5Rozs8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}