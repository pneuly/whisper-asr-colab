{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pneuly/whisper-asr-colab/blob/develop/whisper_asr_colab_ja.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYRELn5Rozs8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import locale\n",
    "import functools\n",
    "from google.colab import files\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "os.environ[\"UV_PRERELEASE\"] = \"if-necessary-or-explicit\"\n",
    "os.environ[\"UV_SYSTEM_PYTHON\"] = \"true\"\n",
    "os.environ[\"UV_NO_PROGRESS\"] = \"true\"\n",
    "for var in [\"UV_BUILD_CONSTRAINT\", \"UV_CONSTRAINT\"]:\n",
    "    os.environ.pop(var, None)\n",
    "\n",
    "# Avoid unnecessary downgrades\n",
    "with open(\"override.txt\", \"w\") as f:\n",
    "    f.writelines(\"\"\"nvidia-cudnn-cu12\n",
    "nvidia-cublas-cu12\n",
    "nvidia-cuda-cupti-cu12\n",
    "nvidia-cuda-nvrtc-cu12\n",
    "nvidia-cuda-runtime-cu12\n",
    "nvidia-cufft-cu12\n",
    "nvidia-curand-cu12\n",
    "nvidia-cusolver-cu12\n",
    "nvidia-cusparse-cu12\n",
    "nvidia-nvjitlink-cu12\n",
    "nvidia-nccl-cu12\n",
    "numpy\n",
    "opentelemetry-api\n",
    "opentelemetry-sdk\n",
    "opentelemetry-semantic-conventions\n",
    "opentelemetry-exporter-otlp-proto-common\n",
    "opentelemetry-exporter-otlp-proto-http\n",
    "opentelemetry-proto\n",
    "\"\"\")\n",
    "os.environ[\"UV_OVERRIDE\"] = \"override.txt\"\n",
    "\n",
    "# @title 自動文字起こし（[Source Code](https://github.com/pneuly/whisper-asr-colab)）{ display-mode: \"form\" }\n",
    "# @markdown <font color=\"red\">以下の設定項目を入力しセルを実行（Ctrl+Enter）</font><br>\n",
    "# ※<b>正常に文字起こしができない場合はstart_time、end_timeを指定して音声を分割して下さい</b>\n",
    "# @markdown <b>（設定項目の説明は下にあります）</b></br>\n",
    "\n",
    "audio = 'https://www.youtube.com/watch?v=xAmEQOqtMvA'  # @param {type:\"string\"}\n",
    "password = \"\"  # @param {type:\"string\"}\n",
    "download_format = \"mp3\"  # @param [\"\", \"mp3\", \"m4a\", \"aac\", \"vorbis\", \"opus\", \"wav\"] {allow-input: true}\n",
    "model_size = \"large-v3-turbo\" # @param [\"large-v3-turbo\", \"large-v3\", \"large-v2\", \"large\", \"medium\", \"small\", \"base\", \"tiny\"] {allow-input: true}\n",
    "diarization = True  # @param {type:\"boolean\"}\n",
    "start_time = \"\"  # @param {type:\"string\"}\n",
    "end_time = \"\"  # @param {type:\"string\"}\n",
    "timestamp_offset = \"\"  # @param {type:\"string\"}\n",
    "skip_silence = True  # @param {type:\"boolean\"}\n",
    "hotwords = \"次に、これです。\" #  {type:\"string\"}\n",
    "batch_size = 1 #  {type:\"number\"}\n",
    "realtime = False  #  {type:\"boolean\"}\n",
    "HUGGING_FACE_TOKEN = \"\"  # @param {type:\"string\"}\n",
    "initial_prompt = \"定刻になりましたので、開始いたします。\"\n",
    "prefix = None\n",
    "vad_filter = False\n",
    "files_to_download = []\n",
    "\n",
    "# @markdown ###<br/><b>〔設定の説明〕</b>\n",
    "# @markdown <b>audio:</b> 文字起こしする音声ファイルの場所<br/>\n",
    "# @markdown 　（例）https://www.youtube.com/...... ：Youtube<br/>\n",
    "# @markdown　　　　230401_1010.mp3 ：手動でアップロードしたファイル<br/>\n",
    "# @markdown　　　　<font color=\"red\">空欄にするとアップロードボタンが表示されます。リリースフォルダからファイルをアップロードしてください</font>\n",
    "# @markdown <br/><b>download_format:</b> Youtube等からダウンロードする際の音声ファイル形式\n",
    "# @markdown <br/><b>model_size:</b> 音声認識のモデルサイズ\n",
    "# @markdown <br/><b>diarization:</b> 発言者別の文字起こしファイルを作成するか\n",
    "# @markdown #### <br/><b><font color= \"blue\">以下は必要な場合のみ設定</font></b>\n",
    "# @markdown <br/><b>password:</b> 音声DL時のパスワード（Webexなど）/音声をパスワード付きzipでアップロードした場合のzipパスワード</b>\n",
    "# @markdown <br/><b>start_time:</b> 開始時間 秒 or hh:mm:ss</b>（指定しない場合は最初から）\n",
    "# @markdown <br/><b>end_time:</b> 終了時間 秒 or hh:mm:ss（指定しない場合は最後まで）\n",
    "# @markdown <br/><b>timestamp_offset:</b> タイムスタンプを指定の時間だけずらす 秒 or hh:mm:ss（指定しない場合はstart_timeと連動）\n",
    "# @markdown <br/><b>skip_silence:</b> 先頭と最後の無音区間を削除\n",
    "## @markdown <br/><b>hotwords:</b> キーワード（次に、これです。は句読点を付けるために入れています。）\n",
    "## @markdown <br/><b>batch_size:</b> 2以上にすると少し早くなります。1の場合と2以上の場合で文字起こし結果が変わります。\n",
    "## @markdown <br/><b>reatime: </b><font color=\"red\">ストリーミングをリアルタイムで文字起こしをする場合のみオンにしてください。</font>\n",
    "\n",
    "# ----- main routine ------\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(__name__)\n",
    "#logger.setLevel(logging.DEBUG)\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "if diarization and HUGGING_FACE_TOKEN == \"\":\n",
    "    raise ValueError(\"HUGGING_FACE_TOKEN にトークンを入力してください\")\n",
    "\n",
    "def _transcribe(audio):\n",
    "    from whisper_asr_colab.asr import ASRWorker\n",
    "    worker = ASRWorker(\n",
    "        audio=audio,\n",
    "        load_model_args={\"model_size_or_path\" : model_size,},\n",
    "        transcribe_args={\n",
    "            \"language\" : \"ja\",\n",
    "            \"initial_prompt\" : initial_prompt,\n",
    "            \"batch_size\" : batch_size,\n",
    "            \"hotwords\" : hotwords,\n",
    "            \"prefix\" : prefix,\n",
    "            \"vad_filter\" : False,}\n",
    "    )\n",
    "\n",
    "    if timestamp_offset:\n",
    "        worker.timestamp_offset = timestamp_offset\n",
    "    results = worker.run()\n",
    "    # gc GPU RAM\n",
    "    del worker\n",
    "    return results\n",
    "\n",
    "\n",
    "def _diarize():\n",
    "    !uv pip install pyannote.audio\n",
    "    from whisper_asr_colab.diarize import DiarizationWorker # noqa: E402\n",
    "    from torch.cuda import empty_cache\n",
    "    empty_cache()\n",
    "    diarizer = DiarizationWorker(\n",
    "        audio=audio,\n",
    "        hugging_face_token = HUGGING_FACE_TOKEN,\n",
    "        )\n",
    "    return diarizer.run()\n",
    "\n",
    "\n",
    "def _convert_audio_if_needed():\n",
    "    from whisper_asr_colab.audio import convert_audio\n",
    "    return convert_audio(audio.local_file_path, download_format)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    !uv pip install git+https://github.com/pneuly/whisper-asr-colab.git@develop\n",
    "\n",
    "    from whisper_asr_colab.audio import Audio # noqa: E402\n",
    "    from whisper_asr_colab.common import unzip_with_password, process_isolator\n",
    "    from whisper_asr_colab.asr import ASR_PROGRESS_FILE\n",
    "    from faster_whisper.utils import download_model\n",
    "\n",
    "    if audio == \"\":\n",
    "        audio = list(files.upload())[0]\n",
    "\n",
    "    if isinstance(audio, str) and audio.endswith('.zip'):\n",
    "        audio = unzip_with_password(audio, password)[0]\n",
    "\n",
    "    audio = Audio(\n",
    "        source = audio,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        download_format=download_format,\n",
    "        password=password,\n",
    "    )\n",
    "\n",
    "    audio.verify_upload = False\n",
    "    audio._load_audio()\n",
    "\n",
    "    download_model(model_size)\n",
    "\n",
    "    result = process_isolator(\n",
    "        _transcribe,\n",
    "        ASR_PROGRESS_FILE,\n",
    "        audio,\n",
    "    )\n",
    "\n",
    "    files_to_download.extend(result.values())\n",
    "\n",
    "    if diarization:\n",
    "        diarized_txt = _diarize()\n",
    "        files_to_download.append(diarized_txt)\n",
    "\n",
    "        print(\"Writing to docx.\")\n",
    "        from whisper_asr_colab.docx_generator import DocxGenerator\n",
    "        doc = DocxGenerator()\n",
    "        doc.txt_to_word(diarized_txt)\n",
    "        files_to_download.append(doc.docfilename)\n",
    "\n",
    "    if audio.is_remote:\n",
    "        # Add audio file to files_to_download\n",
    "        audio_file = _convert_audio_if_needed()\n",
    "        files_to_download.append(audio_file)\n",
    "\n",
    "    # Download files\n",
    "    from whisper_asr_colab.common.utils import download_from_colab\n",
    "    for file in files_to_download:\n",
    "        print(f\"Downloading {file}\")\n",
    "        download_from_colab(file)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
